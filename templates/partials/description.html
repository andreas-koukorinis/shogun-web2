<p align="justify">
  The Shogun Machine learning toolbox provides a wide range of unified and efficient Machine Learning (ML) methods.
  The toolbox seamlessly allows to easily combine multiple data representations, algorithm classes, and general purpose tools.
  This enables both rapid prototyping of data pipelines and extensibility in terms of new algorithms.
  We combine modern software architecture in C++ with both efficient low-level computing backends and
  cutting edge algorithm implementations to solve large-scale Machine Learning problems (yet) on single machines.
</p>
<p align="justify">
  One of Shogun's most exciting features is that you can use the toolbox through a unified interface
  from C++, Python, Octave, R, Java, Lua, C#, etc. This not just means that we are independent of trends in computing languages,
  but it also lets you use Shogun as a vehicle to expose your algorithm to multiple communities.
  We use <a href="http://www.swig.org/" target="_blank">SWIG</a> to enable bidirectional communication between C++ and target languages.
  Shogun runs under Linux/Unix, MacOS, Windows.
</p>
<p align="justify">
  Originally focussing on large-scale kernel methods and bioinformatics (for a list of scientific papers mentioning Shogun,
  see <a href="http://scholar.google.com/scholar?hl=en&q=shogun+toolbox&btnG=&as_sdt=1%2C33&as_sdtp=" target="_blank">here</a>),
  the toolbox saw massive extensions to other fields in recent years. It now offers features that span the whole space of Machine Learning methods,
  including many classical methods in classification, regression, dimensionality reduction, clustering,
  but also more advanced algorithm classes such as metric, multi-task, structured output,
  and online learning, as well as feature hashing, ensemble methods, and optimization, just to name a few.
  Shogun in addition contains a number of exclusive state-of-the art algorithms such as a wealth of efficient SVM implementations,
  Multiple Kernel Learning, kernel hypothesis testing, Krylov methods, etc. All algorithms are supported by a collection of general purpose methods
  for evaluation, parameter tuning, preprocessing, serialisation &amp; I/O, etc; the resulting combinatorial possibilities are huge.
</p>
<p align="justify">
  The wealth of ML open-source software allows us to offer bindings to other sophisticated libraries including:
  <a href="http://www.csie.ntu.edu.tw/~cjlin/libsvm/" target="_blank">LibSVM</a>,
  <a href="http://www.csie.ntu.edu.tw/~cjlin/liblinear/" target="_blank">LibLinear</a>,
  <a href="http://svmlight.joachims.org/" target="_blank">SVMLight</a>,
  <a href="http://cmp.felk.cvut.cz/~xfrancv/ocas/html/" target="_blank">LibOCAS</a>,
  <a href="http://cmp.felk.cvut.cz/~xfrancv/libqp/html/" target="_blank">libqp</a>,
  <a href="http://www.hunch.net/~vw/" target="_blank">VowpalWabbit</a>,
  <a href="http://tapkee.lisitsyn.me/" target="_blank">Tapkee</a>,
  <a href="http://www.public.asu.edu/~jye02/Software/SLEP/" target="_blank">SLEP</a>,
  <a href="http://www.gaussianprocess.org/gpml/code/matlab/doc/" target="_blank">GPML</a> and more.
</p>
<p align="justify">
  Shogun got initiated in 1999 by <a href="http://sonnenburgs.de/soeren" target="_blank">Soeren Sonnenburg</a>&nbsp;and
  <a href="http://www.raetschlab.org/" target="_blank">Gunnar Raetsch</a> (that's where the name ShoGun originates from).
  It is now developed by a <a href="/about">larger team</a>&nbsp;of&nbsp;<a href="http://www.github.com/shogun-toolbox/shogun/wiki/AUTHORS" target="_blank">authors</a>,
  and would not have been possible without the patches and bug reports by various people.
  See <a href="http://www.github.com/shogun-toolbox/shogun/wiki/CONTRIBUTIONS" target="_blank">contributions</a> for a detailed list.
  Statistics on Shogun's development activity can be found on <a href="https://www.openhub.net/p/shogun" target="_blank">openhub</a>.
</p>
